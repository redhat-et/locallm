llama-cpp-python[server]==0.2.80
transformers==4.41.2
pip==24.0
